{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import pandera as pa\n",
    "\n",
    "import pandas as pd\n",
    "from utils.utility import get_cocktail_by_glass, extract_and_validate, generate_date_dim\n",
    "# from utils.sql import transaction_table, glass_table, bar_table, cocktail_table, date_table\n",
    "from utils.data_extractor import APIExtractor, CSVExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"config.yaml\"\n",
    "config = yaml.safe_load(open(\"config.yaml\"))\n",
    "\n",
    "db_config = config[\"DATABASE\"]\n",
    "csv_config = config[\"CSV\"]\n",
    "api_config = config[\"API\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utility import trainsaction_schema, bar_stock_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_stock_param = csv_config[\"bar_stock\"]\n",
    "drink_param = api_config[\"cocktail\"]\n",
    "glass_param = api_config[\"glass\"]\n",
    "bar_param = csv_config[\"bar_stock\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_df = extract_and_validate(parameters=glass_param, extract_func=APIExtractor)\n",
    "glass_list = glass_df[\"glass\"].tolist()\n",
    "cocktail_df = get_cocktail_by_glass(parameters=drink_param, glass_list=glass_list, extract_func=APIExtractor)\n",
    "stock_df = extract_and_validate(parameters=bar_stock_param, extract_func=CSVExtractor, schema=bar_stock_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valencia Cocktail\n",
      "Orgasm\n",
      "Sidecar\n",
      "Zimadori Zinger\n",
      "Thai Coffee\n",
      "Sweet Tooth\n",
      "Winter Rita\n",
      "Porto Flip\n",
      "Royal Gin Fizz\n",
      "Vodka And Tonic\n",
      "Tuxedo Cocktail\n",
      "Paradise\n",
      "Snowball\n",
      "Turf Cocktail\n",
      "Scooter\n",
      "Vodka Martini\n",
      "Zorbatini\n",
      "White Lady\n",
      "Victor\n",
      "Waikiki Beachcomber\n",
      "Yoghurt Cooler\n",
      "Texas Rattlesnake\n",
      "Russian Spring Punch\n",
      "Sea Breeze\n",
      "Winter Paloma\n",
      "Yellow Bird\n",
      "Thai Iced Coffee\n",
      "Quentin\n",
      "Ziemes Martini Apfelsaft\n",
      "Passion Fruit Martini\n",
      "Queen Bee\n",
      "Vermouth Cassis\n"
     ]
    }
   ],
   "source": [
    "for x in transaction_df.drink.unique():\n",
    "    if x not in cocktail_df.drink.unique():\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cocktail_df[['drink']].drop_duplicates().sort_values(by=['drink'])\n",
    "d =transaction_df[['drink']].drop_duplicates().sort_values(by=['drink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Empty DataFrame\n",
       " Columns: [drink]\n",
       " Index: [],\n",
       "                drink\n",
       " 5  Valencia Cocktail)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[c.drink==\"Valencia Cocktail\"] , d[d.drink==\"Valencia Cocktail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bee'S Knees</td>\n",
       "      <td>Bellini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Belgian Blue</td>\n",
       "      <td>Bible Belt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bellini</td>\n",
       "      <td>Big Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bellini Martini</td>\n",
       "      <td>Bijou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bermuda Highball</td>\n",
       "      <td>Bloody Mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Berry Deadly</td>\n",
       "      <td>Bob Marley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between The Sheets</td>\n",
       "      <td>Bora Bora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bible Belt</td>\n",
       "      <td>Boston Sour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Big Red</td>\n",
       "      <td>Boxcar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bijou</td>\n",
       "      <td>Bramble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Black &amp; Tan</td>\n",
       "      <td>Broadside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Black And Brown</td>\n",
       "      <td>Bubble Gum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Black Forest Shake</td>\n",
       "      <td>Caipirinha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Black Russian</td>\n",
       "      <td>Caipirissima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Blackthorn</td>\n",
       "      <td>Campari Beer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bleeding Surgeon</td>\n",
       "      <td>Casa Blanca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Blind Russian</td>\n",
       "      <td>Casino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bloody Maria</td>\n",
       "      <td>Casino Royale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bloody Mary</td>\n",
       "      <td>Chicago Fizz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bloody Punch</td>\n",
       "      <td>Chocolate Drink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     c                d\n",
       "0          Bee'S Knees          Bellini\n",
       "1         Belgian Blue       Bible Belt\n",
       "2              Bellini          Big Red\n",
       "3      Bellini Martini            Bijou\n",
       "4     Bermuda Highball      Bloody Mary\n",
       "5         Berry Deadly       Bob Marley\n",
       "6   Between The Sheets        Bora Bora\n",
       "7           Bible Belt      Boston Sour\n",
       "8              Big Red           Boxcar\n",
       "9                Bijou          Bramble\n",
       "10         Black & Tan        Broadside\n",
       "11     Black And Brown       Bubble Gum\n",
       "12  Black Forest Shake       Caipirinha\n",
       "13       Black Russian     Caipirissima\n",
       "14          Blackthorn     Campari Beer\n",
       "15    Bleeding Surgeon      Casa Blanca\n",
       "16       Blind Russian           Casino\n",
       "17        Bloody Maria    Casino Royale\n",
       "18         Bloody Mary     Chicago Fizz\n",
       "19        Bloody Punch  Chocolate Drink"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = pd.DataFrame()\n",
    "f[\"c\"] = c[i:i+20].reset_index(drop=True)\n",
    "f[\"d\"] = d[j:j+20].reset_index(drop=True) \n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_insert = text(\n",
    "    \"\"\"\n",
    "    MERGE INTO bars T\n",
    "    USING \n",
    "        (SELECT DISTINCT bar \n",
    "        FROM {temp_table}) S\n",
    "    ON T.bar = S.bar\n",
    "    WHEN NOT MATCHED THEN\n",
    "        INSERT (bar) \n",
    "        VALUES (S.bar);\n",
    "    \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    MERGE INTO bars T\n",
      "    USING \n",
      "        (SELECT DISTINCT bar \n",
      "        FROM {temp_table}) S\n",
      "    ON T.bar = S.bar\n",
      "    WHEN NOT MATCHED THEN\n",
      "        INSERT (bar) \n",
      "        VALUES (S.bar);\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(bar_insert.params(temp_table=\"bar_temp_table\").__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df = pd.DataFrame()\n",
    "for param in csv_config[\"transactions\"]:\n",
    "    tmp = extract_and_validate(parameters=param, extract_func=CSVExtractor, schema=trainsaction_schema)\n",
    "    tmp[\"location\"] = param[\"name\"]\n",
    "    transaction_df = pd.concat([transaction_df, tmp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utility import trainsaction_schema, bar_stock_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "# from utils.utility import custom_logger\n",
    "from utils.utility import get_cocktail_by_glass, extract_and_validate, generate_date_dim\n",
    "from sql import glass_insert, cocktail_insert, stock_insert, transaction_insert, bar_insert\n",
    "from sql import bar_table, glass_table, cocktail_table, stock_table, transaction_table, date_table\n",
    "from utils.utility import trainsaction_schema, bar_stock_schema\n",
    "from utils.data_extractor import APIExtractor, CSVExtractor\n",
    "\n",
    "# initialize the custom logger\n",
    "# logger = custom_logger(level=\"INFO\", filename=\"data_pipeline.log\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, \"r\") as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def create_db_connection(config):\n",
    "    db_user = os.environ[\"DB_USER\"]\n",
    "    db_password = os.environ[\"DB_PASSWORD\"]\n",
    "    db_host = os.environ[\"DB_HOST\"]\n",
    "    db_port = os.environ[\"DB_PORT\"]\n",
    "    db_name = config[\"database\"]\n",
    "    return create_engine(f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\")\n",
    "\n",
    "def create_tables(conn):\n",
    "    logger.info(\"Creating tables\")\n",
    "    conn.execute(bar_table)\n",
    "    conn.execute(glass_table)\n",
    "    conn.execute(cocktail_table)\n",
    "    conn.execute(stock_table)\n",
    "    conn.execute(date_table)\n",
    "    conn.execute(transaction_table)\n",
    "    logger.info(\"Tables creation completed\")\n",
    "\n",
    "def load_to_stage(df, con, table_name):\n",
    "    if not df.empty:\n",
    "        logger.info(f\"Loading data into {table_name}\")\n",
    "        df.to_sql(name=table_name, con=con, if_exists=\"replace\", index=False)\n",
    "        logger.info(f\"Loading data into {table_name} completed\")    \n",
    "\n",
    "def load_to_report(query, conn):\n",
    "    logger.info(f\"Loading data into {query}\")\n",
    "    conn.execute(query)\n",
    "    logger.info(f\"Loading data into {query} completed\")\n",
    "\n",
    "def load_data_to_staging(db_config, api_config, csv_config, conn):\n",
    "    logger.info(\"Running load_data_to staging\")\n",
    "    \n",
    "    # extract glass data from API\n",
    "    glass_param = api_config[\"glass\"]\n",
    "    glass_table = db_config[\"glass_table_stage\"]\n",
    "    glass_df = extract_and_validate(parameters=glass_param, extract_func=APIExtractor)\n",
    "    load_to_stage(glass_df, conn, glass_table)\n",
    "    \n",
    "    # cocktail data from API\n",
    "    drink_param = api_config[\"cocktail\"]\n",
    "    drink_table = db_config[\"cocktail_table_stage\"]\n",
    "    glass_list = glass_df[\"glass\"].unique().tolist()\n",
    "    cocktail_df = get_cocktail_by_glass(parameters=drink_param, glass_list=glass_list, extract_func=APIExtractor)\n",
    "    load_to_stage(cocktail_df, conn, drink_table)\n",
    "    \n",
    "    # bar stock data from csv\n",
    "    bar_stock_param = csv_config[\"bar_stock\"]\n",
    "    stock_table = db_config[\"stock_table_stage\"]\n",
    "    stock_df = extract_and_validate(parameters=bar_stock_param, extract_func=CSVExtractor, schema=bar_stock_schema)\n",
    "    load_to_stage(stock_df, conn, stock_table)\n",
    "    \n",
    "    # extract transaction data from csv validate and load into staging table\n",
    "    transaction_table = db_config[\"transaction_table_stage\"]\n",
    "    transaction_df = pd.DataFrame()\n",
    "    for param in csv_config[\"transactions\"]:\n",
    "        tmp = extract_and_validate(parameters=param, extract_func=CSVExtractor, schema=trainsaction_schema)\n",
    "        tmp[\"location\"] = param[\"name\"]\n",
    "        transaction_df = pd.concat([transaction_df, tmp], axis=0, ignore_index=True)\n",
    "    load_to_stage(transaction_df, conn, transaction_table)\n",
    "\n",
    "    # this will be a one time process as the date dimension table will be static\n",
    "    if db_config[\"initial_load\"]:\n",
    "        date_table = db_config[\"date_table\"]\n",
    "        date_df = generate_date_dim(start_date=\"2020-01-01\", end_date=\"2030-12-31\", freq=\"H\")\n",
    "        load_to_stage(date_df, conn, date_table)\n",
    "\n",
    "def update_report_tables_from_staging(db_config, conn):\n",
    "    logger.info(\"Updating report tables from staging\")\n",
    "    # update date bar dimension\n",
    "    bar_sql = bar_insert.format(temp_table=db_config[\"stock_table_stage\"])\n",
    "    conn.execute(bar_sql)\n",
    "\n",
    "    # update glasses table\n",
    "    glass_temp_table = db_config[\"glass_table_stage\"]\n",
    "    load_to_report(glass_insert.format(temp_table=glass_temp_table), conn)\n",
    "    \n",
    "    # update cocktail table\n",
    "    cocktail_temp_table = db_config[\"cocktail_table_stage\"]\n",
    "    load_to_report(cocktail_insert.format(temp_table=cocktail_temp_table), conn)\n",
    "\n",
    "    # update stock table\n",
    "    stock_temp_table = db_config[\"stock_table_stage\"]\n",
    "    load_to_report(stock_insert.format(temp_table=stock_temp_table), conn)\n",
    "    \n",
    "    # update transaction table\n",
    "    transaction_temp_table = db_config[\"transaction_table_stage\"]\n",
    "    load_to_report(transaction_insert.format(temp_table=transaction_temp_table), conn)\n",
    "    \n",
    "    logger.info(\"Report tables update completed\")\n",
    "    \n",
    "config = load_config(\"config.yaml\")\n",
    "csv_config = config[\"CSV\"]\n",
    "api_config = config[\"API\"]\n",
    "db_config = config[\"DATABASE\"]\n",
    "engine = create_db_connection(db_config)\n",
    "    \n",
    "# def main():\n",
    "#     logger.info(\"ETL process started\")\n",
    "#     config = load_config(\"config.yaml\")\n",
    "#     csv_config = config[\"CSV\"]\n",
    "#     api_config = config[\"API\"]\n",
    "#     db_config = config[\"DATABASE\"]\n",
    "#     engine = create_db_connection(db_config)\n",
    "#     conn = engine.connect()\n",
    "#     if db_config[\"initial_load\"]:\n",
    "#         create_tables(conn)\n",
    "#     load_data_to_staging(db_config, api_config, csv_config, conn)\n",
    "#     update_report_tables_from_staging(db_config, conn)\n",
    "#     conn.close()\n",
    "#     logger.info(\"ETL process completed\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_data_insert = \"\"\"INSERT INTO bars (name) VALUES (:1);\"\"\"\n",
    "\n",
    "glass_data_insert = \"\"\"\n",
    "INSERT INTO glasses (name)\n",
    "VALUES (?);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.query(Glass).delete()\n",
    "session.commit()\n",
    "\n",
    "for i in glass_df.itertuples(index=False):\n",
    "    tmp = Glass(**i._asdict())\n",
    "    session.add(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glass</th>\n",
       "      <th>drink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Highball glass</td>\n",
       "      <td>57 Chevy with a White License Plate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Highball glass</td>\n",
       "      <td>747 Drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Highball glass</td>\n",
       "      <td>A Day at the Beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Highball glass</td>\n",
       "      <td>A Furlong Too Late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Highball glass</td>\n",
       "      <td>A Night In Old Mandalay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            glass                                drink\n",
       "0  Highball glass  57 Chevy with a White License Plate\n",
       "1  Highball glass                            747 Drink\n",
       "2  Highball glass                   A Day at the Beach\n",
       "3  Highball glass                   A Furlong Too Late\n",
       "4  Highball glass              A Night In Old Mandalay"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drink_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Highball glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cocktail glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Old-fashioned glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whiskey Glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Collins glass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 glass\n",
       "0       Highball glass\n",
       "1       Cocktail glass\n",
       "2  Old-fashioned glass\n",
       "3        Whiskey Glass\n",
       "4        Collins glass"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glass_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, ForeignKey, DateTime,Sequence\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Bar(Base):\n",
    "    __tablename__ = 'bars'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String)\n",
    "    UniqueConstraint('name')\n",
    "\n",
    "class BarStock(Base):\n",
    "    __tablename__ = 'bar_stock'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    bar_id = Column(Integer, ForeignKey('bars.id'))\n",
    "    glass_id = Column(Integer, ForeignKey('glasses.id'))\n",
    "    stock = Column(Integer)\n",
    "    \n",
    "class Transaction(Base):\n",
    "    __tablename__ = 'transactions'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    drink_id = Column(Integer, ForeignKey('cocktail.id'))\n",
    "    bar_id = Column(Integer, ForeignKey('bars.id'))\n",
    "    date = Column(DateTime, nullable=False)\n",
    "    amount = Column(Integer)\n",
    "    \n",
    "class Glass(Base):\n",
    "    __tablename__ = 'glasses'\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True, nullable=False)\n",
    "    glass = Column(String)\n",
    "    UniqueConstraint('glass')\n",
    "    Sequence(\"seq\",start=1001, increment=1)\n",
    "\n",
    "class Cocktail(Base):\n",
    "    __tablename__ = 'cocktail'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    glass_id = Column(Integer, ForeignKey('glasses.id'))\n",
    "    cocktail = Column(String, nullable=False)\n",
    "    UniqueConstraint('cocktail', 'glass_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_df = pd.DataFrame()\n",
    "for param in csv_config[\"transactions\"]:\n",
    "    tmp = extract_and_validate(parameters=param, extract_func=CSVExtractor, schema=trainsaction_schema)\n",
    "    tmp[\"location\"] = param[\"name\"]\n",
    "    transaction_df = pd.concat([transaction_df, tmp], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_param = api_config[\"glass\"]\n",
    "glass_df = extract_and_validate(parameters=glass_param, extract_func=APIExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(open('config.yaml'))\n",
    "csv_transactions = config['CSV']['transactions']\n",
    "csv_bars = config['CSV']['bar']\n",
    "api_config = config['API']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>budapest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new york</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bar\n",
       "0  budapest\n",
       "1    london\n",
       "2  new york"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(**csv_bars[\"pandas_kwargs\"])[[\"bar\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE = \"qs_warehouse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractData:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "class TransformData:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def transform_data(self):\n",
    "        pass\n",
    "\n",
    "class LoadData:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/116rntps01j3zcbq56ks9h3r0000gn/T/ipykernel_925/89025984.py:10: MovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from utils.custom import custom_logger\n",
    "from sqlalchemy import create_engine, UniqueConstraint, ForeignKey\n",
    "from sqlalchemy import Column, Integer, String, DateTime, DECIMAL\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "loggger = custom_logger()\n",
    "\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"postgresql://hardey:root@localhost:5432/test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transaction(Base):\n",
    "    __tablename__ = \"fact_transactions\"\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    drink_id = Column(Integer, ForeignKey(\"cocktails.id\"), nullable=False)\n",
    "    cocktail_id = Column(Integer, ForeignKey(\"bars.id\"), nullable=False)\n",
    "    date = Column(DateTime, nullable=False)\n",
    "    amount = Column(DECIMAL(2), nullable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transaction_df.to_sql(name=transaction_table, con=engine, if_exists=\"append\", index=False)\n",
    "\n",
    "# generate date dimension table with a grain of 1 hour\n",
    "# this will be a one time process as the date dimension table will be static\n",
    "# date_table = db_config[\"date_table\"]\n",
    "# date_df = generate_date_dim(start_date=\"2020-01-01\", end_date=\"2020-12-31\", freq=\"H\")\n",
    "# date_df.to_sql(name=date_table, con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from utils.utility import custom_logger\n",
    "from utils.utility import get_cocktail_by_glass, extract_and_validate, generate_date_dim\n",
    "from sql import glass_insert, cocktail_insert, stock_insert, transaction_insert, bar_insert\n",
    "from utils.utility import trainsaction_schema, bar_stock_schema\n",
    "from utils.data_extractor import APIExtractor, CSVExtractor\n",
    "\n",
    "# initialize the custom logger\n",
    "logger = custom_logger(level=\"INFO\", filename=\"data_pipeline.log\")\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, \"r\") as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def create_db_connection(config):\n",
    "    db_user = os.environ[\"DB_USER\"]\n",
    "    db_password = os.environ[\"DB_PASSWORD\"]\n",
    "    db_host = os.environ[\"DB_HOST\"]\n",
    "    db_port = os.environ[\"DB_PORT\"]\n",
    "    db_name = config[\"database\"]\n",
    "    return create_engine(f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\")\n",
    "\n",
    "def load_to_stage(df, con, table_name):\n",
    "    if not df.empty:\n",
    "        logger.info(f\"Loading data into {table_name}\")\n",
    "        df.to_sql(name=table_name, con=con, if_exists=\"replace\", index=False)\n",
    "        logger.info(f\"Loading data into {table_name} completed\")    \n",
    "\n",
    "def load_to_report(query, conn):\n",
    "    logger.info(f\"Loading data into {query}\")\n",
    "    conn.execute(query)\n",
    "    logger.info(f\"Loading data into {query} completed\")\n",
    "\n",
    "def extract_transform(db_config, api_config, csv_config, conn):\n",
    "    logger.info(\"Running load_data_to staging\")\n",
    "    \n",
    "    # extract glass data from API\n",
    "    glass_param = api_config[\"glass\"]\n",
    "    glass_table = db_config[\"glass_table_stage\"]\n",
    "    glass_df = extract_and_validate(parameters=glass_param, extract_func=APIExtractor)\n",
    "    load_to_stage(glass_df, conn, glass_table)\n",
    "    \n",
    "    # cocktail data from API\n",
    "    drink_param = api_config[\"cocktail\"]\n",
    "    drink_table = db_config[\"cocktail_table_stage\"]\n",
    "    glass_list = glass_df[\"glass\"].unique().tolist()\n",
    "    cocktail_df = get_cocktail_by_glass(parameters=drink_param, glass_list=glass_list, extract_func=APIExtractor)\n",
    "    load_to_stage(cocktail_df, conn, drink_table)\n",
    "    \n",
    "    # bar stock data from csv\n",
    "    bar_stock_param = csv_config[\"bar_stock\"]\n",
    "    stock_table = db_config[\"stock_table_stage\"]\n",
    "    stock_df = extract_and_validate(parameters=bar_stock_param, extract_func=CSVExtractor, schema=bar_stock_schema)\n",
    "    load_to_stage(stock_df, conn, stock_table)\n",
    "    \n",
    "    # extract transaction data from csv validate and load into staging table\n",
    "    transaction_table = db_config[\"transaction_table_stage\"]\n",
    "    transaction_df = pd.DataFrame()\n",
    "    for param in csv_config[\"transactions\"]:\n",
    "        tmp = extract_and_validate(parameters=param, extract_func=CSVExtractor, schema=trainsaction_schema)\n",
    "        tmp[\"location\"] = param[\"name\"]\n",
    "        transaction_df = pd.concat([transaction_df, tmp], axis=0, ignore_index=True)\n",
    "    load_to_stage(transaction_df, conn, transaction_table)\n",
    "\n",
    "    # this will be a one time process as the date dimension table will be static\n",
    "    if db_config[\"initial_load\"]:\n",
    "        date_table = db_config[\"date_table\"]\n",
    "        date_df = generate_date_dim(start_date=\"2020-01-01\", end_date=\"2030-12-31\", freq=\"H\")\n",
    "        load_to_stage(date_df, conn, date_table)\n",
    "\n",
    "def load(db_config, conn):\n",
    "    logger.info(\"Updating report tables from staging\")\n",
    "    \n",
    "    # update bars table\n",
    "    bar_sql = bar_insert.format(temp_table=db_config[\"stock_table_stage\"])\n",
    "    conn.execute(bar_sql)\n",
    "\n",
    "    # update glasses table\n",
    "    glass_temp_table = db_config[\"glass_table_stage\"]\n",
    "    load_to_report(glass_insert.format(temp_table=glass_temp_table), conn)\n",
    "    \n",
    "    # update cocktails table\n",
    "    cocktail_temp_table = db_config[\"cocktail_table_stage\"]\n",
    "    load_to_report(cocktail_insert.format(temp_table=cocktail_temp_table), conn)\n",
    "\n",
    "    # update stock table\n",
    "    stock_temp_table = db_config[\"stock_table_stage\"]\n",
    "    load_to_report(stock_insert.format(temp_table=stock_temp_table), conn)\n",
    "    \n",
    "    # update transaction table\n",
    "    transaction_temp_table = db_config[\"transaction_table_stage\"]\n",
    "    load_to_report(transaction_insert.format(temp_table=transaction_temp_table), conn)\n",
    "    \n",
    "    logger.info(\"Report tables update completed\")\n",
    "    \n",
    "\n",
    "def main():\n",
    "    logger.info(\"ETL process started\")\n",
    "    config = load_config(\"config.yaml\")\n",
    "    csv_config = config[\"CSV\"]\n",
    "    api_config = config[\"API\"]\n",
    "    db_config = config[\"DATABASE\"]\n",
    "    engine = create_db_connection(db_config)\n",
    "    conn = engine.connect()\n",
    "    extract_transform(db_config, api_config, csv_config, conn)\n",
    "    load(db_config, conn)\n",
    "    conn.close()\n",
    "    logger.info(\"ETL process completed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import logging\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from typing import List, Dict, Callable, Optional\n",
    "\n",
    "\n",
    "\n",
    "# Schema validation for transaction and bar data\n",
    "bar_stock_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "    \"glass_type\": pa.Column(str,nullable=False),\n",
    "    \"stock\": pa.Column(int, checks=pa.Check.gt(-1), nullable=False), # check there is no negative stock\n",
    "    \"bar\": pa.Column(str, nullable=False),\n",
    "    },\n",
    ")\n",
    "\n",
    "trainsaction_schema = pa.DataFrameSchema(\n",
    "    {\n",
    "    \"time\": pa.Column(\"datetime64[ns]\", nullable=False),\n",
    "    \"drink\": pa.Column(str, nullable=False),\n",
    "    \"amount\": pa.Column(float, checks=pa.Check.gt(0), nullable=False), # check all sales amount is greater than 0\n",
    "    },\n",
    ")\n",
    "\n",
    "def custom_logger(level: str = \"INFO\", filename: str = \"data_pipeline.log\"):\n",
    "    \"\"\"\n",
    "    This function returns a custom logger object.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    logger: logging.Logger\n",
    "        Logger object.\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "    formatter = logging.Formatter('%(asctime)s:%(name)s:%(levelname)s:%(message)s')\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    stream_handler.setLevel(level)\n",
    "    logger.addHandler(stream_handler)\n",
    "    # file_handler = logging.FileHandler(filename)\n",
    "    # file_handler.setLevel(level)\n",
    "    # file_handler.setFormatter(formatter)\n",
    "    # logger.addHandler(file_handler)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def generate_date_dim(start_date:str, end_date:str, freq:str =\"H\"):\n",
    "    \"\"\" generate date attribute for the given range and returns it as a DataFrame.\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    start_date : str\n",
    "        Start date in \"YYYY-MM-DD\" format.\n",
    "        \n",
    "    end_date : str\n",
    "        End date in \"YYYY-MM-DD\" format.\n",
    "        \n",
    "    freq : str\n",
    "        Frequency of date intervals (default is \"H\" for hourly).\n",
    "        \n",
    "    Returns \n",
    "    -------\n",
    "    df: pd.DataFrame\n",
    "        DataFrame containing date-related columns.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"date\": pd.date_range(start=start_date, end=end_date,freq=freq)})\n",
    "    df['date_id'] = df.date.dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    df['calender_day'] = df.date.dt.day\n",
    "    df['hour'] = df.date.dt.hour\n",
    "    df['week_number'] = df.date.dt.isocalendar().week\n",
    "    df['month'] = df.date.dt.strftime('%B')\n",
    "    df['quarter'] = df.date.dt.quarter\n",
    "    df['year'] = df.date.dt.year\n",
    "    df['day_name'] = df.date.dt.strftime('%A')\n",
    "    df['date'] = df.date.dt.date\n",
    "    return df\n",
    "\n",
    "def get_cocktail_by_glass(parameters: Dict, glass_list: List[str], extract_func: Callable) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    get list of cocktails based on the glass type from the API\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    parameters : Dict\n",
    "        This is the parameters for the APIExtractor class constructor.\n",
    "        \n",
    "    glass_list : List[str]\n",
    "        List of glass types.\n",
    "        \n",
    "    extract_func : Callable\n",
    "        This is the APIExtractor class.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df: pd.DataFrame\n",
    "        DataFrame containing cocktails by glass type.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(columns=[\"glass\", \"drink\"])\n",
    "    for glass in glass_list:\n",
    "        current_param = copy.deepcopy(parameters)\n",
    "        current_param[\"request_obj\"][\"url\"] = current_param[\"request_obj\"][\"url\"].format(glass=glass)\n",
    "        temp = extract_func(**current_param).fetch_data()\n",
    "        temp[\"glass\"] = glass\n",
    "        df = pd.concat([df, temp], axis=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_and_validate(parameters: Dict, extract_func: Callable, schema: Optional[pa.DataFrameSchema] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts the data specification in the parameters Dict using the \n",
    "    extract_func and Validates the data with the schema.\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    parameters : Dict\n",
    "        This is the Parameters for the extract_func.\n",
    "\n",
    "    extract_func : Callable\n",
    "        This is the extract function which can be a class of  of (CSVExtractor| APIExtractor).\n",
    "        \n",
    "    schema : pa.DataFrameSchema\n",
    "        This is the pandera DataFrameSchema object.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing extracted and validated data.\n",
    "        \n",
    "    \"\"\"\n",
    "    logger = custom_logger(level=\"INFO\", filename=\"data_pipeline.log\")\n",
    "    try :\n",
    "        df = extract_func(**parameters).fetch_data()\n",
    "        if schema is None:\n",
    "            return df\n",
    "        validated_df = schema.validate(df, lazy=True)\n",
    "        return validated_df\n",
    "    except pa.errors.SchemaErrors as e:\n",
    "        error_df = e.failure_cases\n",
    "        errors = list(zip(error_df.column, error_df.check))\n",
    "        logger.error(f\"Schema validation failed for columns {errors} in {parameters['name']} file\", exc_info=True)\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from utils.utility import custom_logger\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Optional, Any as AnyType\n",
    "\n",
    "\n",
    "logger = custom_logger(level=\"INFO\", filename=\"data_pipeline.log\")\n",
    "\n",
    "class BaseExtractor(ABC):\n",
    "    \"\"\"\n",
    "    This class defines the common interface for all data extraction methods.\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def fetch_data(self, **kwargs):\n",
    "        pass\n",
    "    \n",
    "class CSVExtractor(BaseExtractor):\n",
    "    \"\"\"\n",
    "    Extract data from a CSV file with the specified parameters.\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        Description for the data source.\n",
    "        \n",
    "    pandas_kwargs : Dict[AnyType,AnyType]\n",
    "        Parameters passed to pandas.read_csv function.\n",
    "        \n",
    "    columns_mapping : Optional[Dict[AnyType,AnyType]]\n",
    "        Key, Value pairs of columns that should be renamed.\n",
    "        \n",
    "    capitalize_columns : Optional[List[str]]\n",
    "        List of columns that should be capitalized.\n",
    "        \n",
    "    drop_columns : Optional[List[AnyType]] \n",
    "        List of columns that should be dropped from the dataframe.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, name: str, \n",
    "        pandas_kwargs: Dict[AnyType,AnyType], \n",
    "        capitalize_columns: Optional[List[str]] = None,\n",
    "        columns_mapping: Optional[Dict[AnyType,AnyType]]= None, \n",
    "        drop_columns: Optional[List[AnyType]]= None\n",
    "        ) -> None:\n",
    "        self.name = name\n",
    "        self.pandas_kwargs = pandas_kwargs\n",
    "        self.capitalize_columns= capitalize_columns\n",
    "        self.columns_mapping = columns_mapping\n",
    "        self.drop_columns = drop_columns\n",
    "\n",
    "    def fetch_data(self) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        This method reads data from a CSV file using the configurations \n",
    "        passed to the class constructor and returns it as a DataFrame.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        df: pd.DataFrame\n",
    "            DataFrame containing extracted data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Getting {self.name} data from {self.pandas_kwargs['filepath_or_buffer']}\")\n",
    "            df = pd.read_csv(**self.pandas_kwargs)\n",
    "            if self.drop_columns:\n",
    "                df.drop(columns=self.drop_columns, inplace=True)\n",
    "            if self.columns_mapping:\n",
    "                df.rename(columns=self.columns_mapping, inplace=True)\n",
    "            if self.capitalize_columns: # capitalize all words in the specified columns\n",
    "                df[self.capitalize_columns] = df[self.capitalize_columns].map(str.title)\n",
    "            df.drop_duplicates(inplace=True) # remove duplicates\n",
    "            logger.info(f\"Finished getting {self.name} data from {self.pandas_kwargs['filepath_or_buffer']}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting {self.name} data with the specified configuration\", exc_info=True)\n",
    "            raise e\n",
    "\n",
    "class APIExtractor(BaseExtractor):\n",
    "    \"\"\"\n",
    "    Extract data from a Web API with the specified parameters.\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        Description for the data source.\n",
    "        \n",
    "    request_obj : Dict[AnyType,AnyType]\n",
    "        Parameters passed to the requests.get function.\n",
    "        \n",
    "    data_field : str\n",
    "        The key for the data field in the API response.\n",
    "        \n",
    "    capitalize_columns : Optional[List[str]]\n",
    "        List of columns that should be capitalized.     \n",
    "\n",
    "    columns_mapping : Optional[Dict[AnyType,AnyType]]\n",
    "        Key, Value pairs of columns that should be renamed.\n",
    "        \n",
    "    drop_columns : Optional[List[AnyType]] \n",
    "        List of columns that should be dropped from the dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        name: str,\n",
    "        request_obj: Dict[AnyType,AnyType], \n",
    "        data_field: str, \n",
    "        capitalize_columns: Optional[List[str]] = None,\n",
    "        columns_mapping: Optional[Dict[AnyType,AnyType]]=None,\n",
    "        drop_columns: Optional[List[AnyType]]=None\n",
    "        ):\n",
    "        self.name = name\n",
    "        self.request_obj = request_obj\n",
    "        self.data_field = data_field\n",
    "        self.capitalize_columns = capitalize_columns\n",
    "        self.columns_mapping = columns_mapping\n",
    "        self.drop_columns = drop_columns\n",
    "        \n",
    "    def fetch_data(self) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        This method reads data from an API using the configurations \n",
    "        passed to the class constructor and returns it as a DataFrame.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        df: pd.DataFrame\n",
    "            DataFrame containing extracted data.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Getting {self.name} data from {self.request_obj['url']}\")\n",
    "        try:\n",
    "            resp = requests.get(**self.request_obj)\n",
    "            resp = resp.json()[self.data_field]   \n",
    "            df = pd.DataFrame(resp)\n",
    "            if self.drop_columns:\n",
    "                df.drop(columns=self.drop_columns, inplace=True)\n",
    "            if self.columns_mapping:\n",
    "                df.rename(columns=self.columns_mapping, inplace=True)  \n",
    "            df.drop_duplicates(inplace=True) # remove duplicates\n",
    "            if self.capitalize_columns: # capitalize all words in the specified columns\n",
    "                df[self.capitalize_columns] = df[self.capitalize_columns].map(str.title)\n",
    "            logger.info(f\"Finished getting {self.name} data from {self.request_obj['url']}\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting {self.name} data with the specified configuration\", exc_info=True)\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine, UniqueConstraint, ForeignKey\n",
    "from sqlalchemy import Column, Integer, String, DateTime, DECIMAL\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Bar(Base):\n",
    "    __tablename__ = 'bars'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    bar = Column(String, nullable=False)\n",
    "    UniqueConstraint('bar')\n",
    "\n",
    "class Glass(Base):\n",
    "    __tablename__ = 'glasses'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    glass = Column(String, nullable=False)\n",
    "    UniqueConstraint('glass')\n",
    "    \n",
    "class Cocktail(Base):\n",
    "    __tablename__ = 'cocktails'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    glass_id = Column(Integer, ForeignKey('glasses.id'), nullable=False)\n",
    "    drink = Column(String, nullable=False)\n",
    "    UniqueConstraint('drink')\n",
    "    \n",
    "        \n",
    "class BarStock(Base):\n",
    "    __tablename__ = 'bar_stock'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    bar_id = Column(Integer, ForeignKey('bars.id'), nullable=False)\n",
    "    glass_id = Column(Integer, ForeignKey('glasses.id'), nullable=False)\n",
    "    stock = Column(Integer)\n",
    "    \n",
    "class Transaction(Base):\n",
    "    __tablename__ = 'transactions'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    drink_id = Column(Integer, ForeignKey('cocktails.id'), nullable=False)\n",
    "    cocktail_id = Column(Integer, ForeignKey('bars.id'), nullable=False)\n",
    "    date = Column(DateTime, nullable=False)\n",
    "    amount = Column(DECIMAL(2), nullable=False)\n",
    "    \n",
    "\n",
    "class Date(Base):\n",
    "    __tablename__ = 'dim_date'\n",
    "    date_id = Column(String, primary_key=True, nullable=False)\n",
    "    date = Column(DateTime, nullable=False)\n",
    "    day_name = Column(String, nullable=False)\n",
    "    calendar_day = Column(Integer, nullable=False)\n",
    "    week_number = Column(Integer, nullable=False)\n",
    "    hour = Column(Integer, nullable=False)\n",
    "    year = Column(Integer, nullable=False)\n",
    "    quarter = Column(Integer, nullable=False)\n",
    "    month = Column(Integer, nullable=False)\n",
    "    hour = Column(Integer, nullable=False)\n",
    "\n",
    "bar_insert = \"\"\"\n",
    "MERGE INTO bars T\n",
    "USING \n",
    "    (SELECT DISTINCT bar \n",
    "    FROM {temp_table}) S\n",
    "ON T.bar = S.bar\n",
    "WHEN NOT MATCHED THEN\n",
    "\tINSERT (bar) \n",
    "    VALUES (S.bar);\n",
    "\"\"\"\n",
    "\n",
    "glass_insert = \"\"\"\n",
    "MERGE INTO glasses T\n",
    "USING {temp_table} S\n",
    "ON T.glass = S.glass\n",
    "WHEN NOT MATCHED THEN \n",
    "\tINSERT (glass) \n",
    "    VALUES (S.glass)\n",
    "\"\"\"\n",
    "\n",
    "cocktail_insert = \"\"\"\n",
    "MERGE INTO cocktails T\n",
    "USING \n",
    "    (SELECT g.id AS glass_id , c.drink \n",
    "    FROM {temp_table} c\n",
    "    LEFT JOIN glasses g\n",
    "    ON c.glass=g.glass\n",
    "    ) S\n",
    "ON T.glass_id = S.glass_id AND T.drink = S.drink\n",
    "WHEN NOT MATCHED THEN \n",
    "    INSERT (glass_id, drink) \n",
    "    VALUES (S.glass_id, S.drink)\n",
    "\"\"\"\n",
    "\n",
    "stock_insert = \"\"\"\n",
    "MERGE INTO bar_stock T\n",
    "USING \n",
    "    (SELECT b.id AS bar_id, g.id AS glass_id, stock \n",
    "    FROM {temp_table} ts\n",
    "    LEFT JOIN bars b\n",
    "    ON ts.bar=b.bar\n",
    "    LEFT JOIN glasses g\n",
    "    ON ts.glass_type=g.glass\n",
    "    ) S\n",
    "ON T.bar_id = S.bar_id AND T.glass_id = S.glass_id\n",
    "WHEN NOT MATCHED THEN \n",
    "    INSERT (bar_id, glass_id, stock) \n",
    "    VALUES (S.bar_id, S.glass_id, S.stock)\n",
    "\"\"\"\n",
    "    \n",
    "transaction_insert = \"\"\"\n",
    "INSERT INTO fact_transactions (bar_id, cocktail_id, amount, date)\n",
    "SELECT b.id AS bar_id, c.id AS cocktail_id, amount, tx.time\n",
    "    FROM {temp_table} tx\n",
    "    INNER JOIN bars b ON tx.location=b.bar\n",
    "    INNER JOIN cocktails c ON tx.drink=c.cocktail\n",
    "\"\"\"\n",
    "\n",
    "if __name__=='__main__':\n",
    "    db_user = os.environ[\"DB_USER\"]\n",
    "    db_password = os.environ[\"DB_PASSWORD\"]\n",
    "    db_host = os.environ[\"DB_HOST\"]\n",
    "    db_port = os.environ[\"DB_PORT\"]\n",
    "    db_name = os.environ[\"DB_NAME\"]\n",
    "    \n",
    "    engine = create_engine(f\"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}\")\n",
    "    Base.metadata.create_all(engine, checkfirst=True)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    session.commit()\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export DB_USER=\"hardey\"\n",
    "export DB_PASSWORD=\"root\"\n",
    "export DB_HOST=\"localhost\"\n",
    "export DB_PORT=\"5432\"\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DimGlass\n",
    "-\n",
    "GlassID PK int\n",
    "Name varchar(200) \n",
    "\n",
    "DimBar\n",
    "-------\n",
    "BarID PK int\n",
    "Name varchar(200) \n",
    "\n",
    "FactTransactions\n",
    "----\n",
    "TransactionID PK \n",
    "BarID FK >- DimBar.BarID\n",
    "CockTailID FK >- DimCockTail.CockTailID\n",
    "Amount \n",
    "Date\n",
    "\n",
    "\n",
    "DimCockTail\n",
    "------------\n",
    "CockTailID PK int\n",
    "Name varchar(200) \n",
    "Amount\n",
    "\n",
    "\n",
    "DimDate\n",
    "----------\n",
    "DateID PK int"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
